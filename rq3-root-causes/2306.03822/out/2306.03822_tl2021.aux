\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Thompson1995ValuationOP}
\citation{Broadie2004ASM,Jaillet1990VariationalIA,Longstaff2001ValuingAO,Rogers2002MonteCV}
\citation{Bardou2007WhenAS,Bardou2009OptimalQF,BarreraEsteve2006NumericalMF,Jaillet2004ValuationOC,LariLavassani2002ADV,Thompson1995ValuationOP}
\citation{Longstaff2001ValuingAO}
\citation{BarreraEsteve2006NumericalMF,Longstaff2001ValuingAO}
\citation{Pags2004OptimalQM}
\citation{Bardou2009OptimalQF}
\providecommand \oddpage@label [2]{}
\citation{GobetMunos}
\citation{BarreraEsteve2006NumericalMF}
\citation{Bardou2009OptimalQF,BarreraEsteve2006NumericalMF}
\citation{BarreraEsteve2006NumericalMF}
\citation{Bardou2007WhenAS}
\@writefile{toc}{\contentsline {section}{\numberline {1}On swing contracts}{3}{section.1}\protected@file@percent }
\newlabel{sec1}{{1}{3}{On swing contracts}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Description}{3}{subsection.1.1}\protected@file@percent }
\newlabel{loc_const}{{1.1}{3}{Description}{equation.1.1}{}}
\newlabel{glob_const}{{1.2}{3}{Description}{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Physical space}{3}{subsection.1.2}\protected@file@percent }
\newlabel{physical_space}{{1.2}{3}{Physical space}{subsection.1.2}{}}
\citation{Bardou2009OptimalQF}
\citation{Bardou2009OptimalQF,BarreraEsteve2006NumericalMF}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of swing physical space with $q_{\qopname  \relax m{min}} = 0, q_{\qopname  \relax m{max}} = 180, Q_{\qopname  \relax m{min}} = 1300, Q_{\qopname  \relax m{max}} = 1900$ and 12 exercise dates.\relax }}{4}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{physical space swing}{{1}{4}{Illustration of swing physical space with $q_{\min } = 0, q_{\max } = 180, Q_{\min } = 1300, Q_{\max } = 1900$ and 12 exercise dates.\relax }{figure.caption.2}{}}
\newlabel{range_cum_vol}{{1.5}{4}{Physical space}{equation.1.5}{}}
\newlabel{intervalle_control}{{1.6}{4}{Physical space}{equation.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Pricing and sensitivity calculus}{4}{subsection.1.3}\protected@file@percent }
\newlabel{pricing}{{1.3}{4}{Pricing and sensitivity calculus}{subsection.1.3}{}}
\citation{Bardou2007WhenAS}
\citation{BarreraEsteve2006NumericalMF}
\citation{BarreraEsteve2006NumericalMF,Jaillet2004ValuationOC}
\newlabel{actual_set_adm_const_case}{{1.8}{5}{Pricing and sensitivity calculus}{equation.1.8}{}}
\newlabel{pricing_swing_formula}{{1.9}{5}{Pricing and sensitivity calculus}{equation.1.9}{}}
\newlabel{swing_init_price}{{1.10}{5}{Pricing and sensitivity calculus}{equation.1.10}{}}
\citation{Bardou2009OptimalQF,BarreraEsteve2006NumericalMF}
\newlabel{hjm_model}{{1.12}{6}{Pricing and sensitivity calculus}{equation.1.12}{}}
\newlabel{spot_model}{{1.13}{6}{Pricing and sensitivity calculus}{equation.1.13}{}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{1}{Envelope theorem}}{6}{theorem.1}\protected@file@percent }
\newlabel{env_thm}{{1}{6}{Pricing and sensitivity calculus}{theorem.1}{}}
\@writefile{thm}{\contentsline {Proposition}{{Proposition}{1}{}}{7}{Proposition.1}\protected@file@percent }
\@writefile{thm}{\contentsline {proof}{{Proof}{1}{}}{7}{proof.1}\protected@file@percent }
\citation{BarreraEsteve2006NumericalMF,Longstaff2001ValuingAO}
\citation{BarreraEsteve2006NumericalMF}
\citation{LariLavassani2002ADV}
\newlabel{param_prob_init}{{1.14}{8}{Pricing and sensitivity calculus}{equation.1.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Swing pricing: A global optimization approach}{8}{section.2}\protected@file@percent }
\newlabel{sec2}{{2}{8}{Swing pricing: A global optimization approach}{section.2}{}}
\citation{BarreraEsteve2006NumericalMF}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Optimal consumption profile as a function of the payoff.\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{decision_profile}{{2}{9}{Optimal consumption profile as a function of the payoff.\relax }{figure.caption.3}{}}
\newlabel{strategy_param1}{{2.1}{9}{Swing pricing: A global optimization approach}{equation.2.1}{}}
\newlabel{q_const_loc}{{2.2}{9}{Swing pricing: A global optimization approach}{equation.2.2}{}}
\citation{BarreraEsteve2006NumericalMF}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Explicit Payoff-Volume parameterization (\textit  {PV strat})}{10}{subsection.2.1}\protected@file@percent }
\newlabel{strat_qty2}{{2.3}{10}{Explicit Payoff-Volume parameterization (\textit {PV strat})}{equation.2.3}{}}
\@writefile{thm}{\contentsline {remark}{{Remark}{1}{Importance of function $M$}}{10}{remark.1}\protected@file@percent }
\newlabel{rq1}{{1}{10}{Explicit Payoff-Volume parameterization (\textit {PV strat})}{remark.1}{}}
\@writefile{thm}{\contentsline {remark}{{Remark}{2}{Remaining capacity \textit {Versus} Cumulative Consumption}}{10}{remark.2}\protected@file@percent }
\newlabel{rq2}{{2}{10}{Explicit Payoff-Volume parameterization (\textit {PV strat})}{remark.2}{}}
\citation{Hornik1989MultilayerFN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Network parameterization (\textit  {NN strat})}{11}{subsection.2.2}\protected@file@percent }
\newlabel{nn_params}{{2.2}{11}{Neural Network parameterization (\textit {NN strat})}{subsection.2.2}{}}
\newlabel{nn_function_rep}{{2.4}{11}{Neural Network parameterization (\textit {NN strat})}{equation.2.4}{}}
\citation{BarreraEsteve2006NumericalMF}
\newlabel{param_space}{{2.5}{12}{Neural Network parameterization (\textit {NN strat})}{equation.2.5}{}}
\newlabel{nn_parame}{{2.6}{12}{Neural Network parameterization (\textit {NN strat})}{equation.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of (deep) neural network architecture.\relax }}{12}{figure.caption.4}\protected@file@percent }
\newlabel{nn_representation}{{3}{12}{Illustration of (deep) neural network architecture.\relax }{figure.caption.4}{}}
\@writefile{thm}{\contentsline {remark}{{Remark}{3}{\textit {PV strat Versus NN strat}}}{12}{remark.3}\protected@file@percent }
\citation{Kushner2003StochasticAA,Robbins2007ASA}
\citation{Rumelhart1986LearningIR}
\citation{EonBottou1998OnlineLA,pmlr-v84-chee18a,Robbins1971ACT}
\citation{Baydin2017AutomaticDI,Paszke2017AutomaticDI}
\citation{Dauphin2014IdentifyingAA,sgdSaddlePoints}
\@writefile{toc}{\contentsline {section}{\numberline {3}Stochastic optimization}{13}{section.3}\protected@file@percent }
\newlabel{training_part}{{3}{13}{Stochastic optimization}{section.3}{}}
\newlabel{stoch_algo_iter}{{3.1}{13}{Stochastic optimization}{equation.3.1}{}}
\newlabel{hyp_DS}{{3.2}{13}{Stochastic optimization}{equation.3.2}{}}
\newlabel{iter_sgd_MC_mini_batch}{{3.3}{13}{Stochastic optimization}{equation.3.3}{}}
\citation{Kingma2015AdamAM}
\citation{sgdMoment}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Saddle points illustration. $(x, y) \DOTSB \mapstochar \rightarrow x^3 - 3xy^2$ (on left) and $(x, y) \DOTSB \mapstochar \rightarrow x^2 - y^2$ (on right). The point $(0,0)$ is a saddle point.\relax }}{14}{figure.caption.5}\protected@file@percent }
\newlabel{saddle_pts}{{4}{14}{Saddle points illustration. $(x, y) \mapsto x^3 - 3xy^2$ (on left) and $(x, y) \mapsto x^2 - y^2$ (on right). The point $(0,0)$ is a saddle point.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Adaptive Moment Estimation (Adam)}{14}{subsection.3.1}\protected@file@percent }
\newlabel{langevin_iter}{{3.4}{14}{Adaptive Moment Estimation (Adam)}{equation.3.4}{}}
\newlabel{sq_elt_grad}{{3.5}{14}{Adaptive Moment Estimation (Adam)}{equation.3.5}{}}
\newlabel{div_elt_grad}{{3.6}{14}{Adaptive Moment Estimation (Adam)}{equation.3.6}{}}
\citation{Defossez2020ASC,Zou2018ASC}
\citation{Welling2011BayesianLV}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Adam updating. $\lambda $ is a small correction term to avoid division by zero. $\odot $ denotes elementwise multiplication and $\oslash $ denotes elementwise division defined in \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {sq_elt_grad}\unskip \@@italiccorr )}} and \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {div_elt_grad}\unskip \@@italiccorr )}}. $Id_q$ represents the $q \times q$ identity matrix.\relax }}{15}{algorithm.1}\protected@file@percent }
\newlabel{alg:algorithm1}{{1}{15}{Adam updating. $\lambda $ is a small correction term to avoid division by zero. $\odot $ denotes elementwise multiplication and $\oslash $ denotes elementwise division defined in \eqref {sq_elt_grad} and \eqref {div_elt_grad}. $Id_q$ represents the $q \times q$ identity matrix.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Preconditioned Stochastic Gradient Langevin Dynamics (PSGLD)}{15}{subsection.3.2}\protected@file@percent }
\citation{addgaussnoise}
\citation{Dalalyan2014TheoreticalGF,Dalalyan2017FurtherAS}
\citation{Pags2020UnadjustedLA}
\citation{bras2022langevin,PierreLangevin,Jospin_2022}
\citation{PierreLangevin}
\citation{Li2016PreconditionedSG}
\newlabel{langevin_sde}{{3.7}{16}{Preconditioned Stochastic Gradient Langevin Dynamics (PSGLD)}{equation.3.7}{}}
\newlabel{langevin_euler}{{3.8}{16}{Preconditioned Stochastic Gradient Langevin Dynamics (PSGLD)}{equation.3.8}{}}
\newlabel{sde_gen}{{3.9}{16}{Preconditioned Stochastic Gradient Langevin Dynamics (PSGLD)}{equation.3.9}{}}
\citation{langcvg,durmus2018highdimensional}
\citation{bras:hal-03891234,Pags2020UnadjustedLA}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces PSGLD updating. We take $\sigma _n = \sigma $ and $\gamma _n = \gamma $. $\odot $ and $\oslash $ are defined in \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {sq_elt_grad}\unskip \@@italiccorr )}} and \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {div_elt_grad}\unskip \@@italiccorr )}}\relax }}{17}{algorithm.2}\protected@file@percent }
\newlabel{alg:algorithm2}{{2}{17}{PSGLD updating. We take $\sigma _n = \sigma $ and $\gamma _n = \gamma $. $\odot $ and $\oslash $ are defined in \eqref {sq_elt_grad} and \eqref {div_elt_grad}\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Adam versus PSGLD}{17}{subsection.3.3}\protected@file@percent }
\newlabel{compar_algo}{{3.3}{17}{Adam versus PSGLD}{subsection.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results for \textit  {PV strat} using Adam optimization algorithm. Values in brackets are confidence intervals (95\%). Column ``time'' includes both training and valuation times.\relax }}{17}{table.caption.6}\protected@file@percent }
\newlabel{results_explicit_param_comp}{{1}{17}{Results for \textit {PV strat} using Adam optimization algorithm. Values in brackets are confidence intervals (95\%). Column \q {time} includes both training and valuation times.\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results for \textit  {PV strat} using PSGLD optimization algorithm. Values in brackets are confidence intervals (95\%). Column ``time'' includes both training and valuation times. We used $N = 1000$ iterations and $\lambda = 1\cdot e^{-10}$.\relax }}{18}{table.caption.7}\protected@file@percent }
\newlabel{results_psgld_explicit_param_comp}{{2}{18}{Results for \textit {PV strat} using PSGLD optimization algorithm. Values in brackets are confidence intervals (95\%). Column \q {time} includes both training and valuation times. We used $N = 1000$ iterations and $\lambda = 1\cdot e^{-10}$.\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results for \textit  {NN strat} using Adam optimization algorithm. For the neural network architecture, we used 2 hidden layers ($I = 2$) with 10 units per layer ($q_1 = 10, q_2 = 10$). Values in brackets are confidence intervals (95\%). Columns ``time'' includes the training and the valuation times.\relax }}{18}{table.caption.8}\protected@file@percent }
\newlabel{results_nn_param_1_comp}{{3}{18}{Results for \textit {NN strat} using Adam optimization algorithm. For the neural network architecture, we used 2 hidden layers ($I = 2$) with 10 units per layer ($q_1 = 10, q_2 = 10$). Values in brackets are confidence intervals (95\%). Columns \q {time} includes the training and the valuation times.\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results for \textit  {NN strat} using PSGLD optimization algorithm. For the neural network architecture, we used 2 hidden layers ($I = 2$) with 10 units per layer ($q_1 = 10, q_2 = 10$). Values in brackets are confidence intervals (95\%). Columns ``time'' includes the training and the valuation times. We used $N = 1000$ iterations and $\lambda = 1\cdot e^{-10}$.\relax }}{18}{table.caption.9}\protected@file@percent }
\newlabel{results_psgld_nn_param_comp}{{4}{18}{Results for \textit {NN strat} using PSGLD optimization algorithm. For the neural network architecture, we used 2 hidden layers ($I = 2$) with 10 units per layer ($q_1 = 10, q_2 = 10$). Values in brackets are confidence intervals (95\%). Columns \q {time} includes the training and the valuation times. We used $N = 1000$ iterations and $\lambda = 1\cdot e^{-10}$.\relax }{table.caption.9}{}}
\citation{BarreraEsteve2006NumericalMF}
\citation{Bardou2009OptimalQF}
\citation{Pan2010ASO}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Delta forward for setting of case 1 (left) and case 2 (right) using \textit  {PV strat} and \textit  {NN strat}.\relax }}{19}{figure.caption.10}\protected@file@percent }
\newlabel{deltas_forward}{{5}{19}{Delta forward for setting of case 1 (left) and case 2 (right) using \textit {PV strat} and \textit {NN strat}.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Practitioner's corner: Transfer learning}{19}{subsection.3.4}\protected@file@percent }
\newlabel{transfer_learn}{{3.4}{19}{Practitioner's corner: Transfer learning}{subsection.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results for a one-year swing contract. Values in brackets are confidence intervals (95\%). The valuation was performed with a sample of size $1 \cdot e^8$. For the training we used $N = 1000$ iterations. $T_{train}$ denotes the training time and $T_{eval}$ the valuation time.\relax }}{19}{table.caption.11}\protected@file@percent }
\newlabel{one_year_swing_baseline}{{5}{19}{Results for a one-year swing contract. Values in brackets are confidence intervals (95\%). The valuation was performed with a sample of size $1 \cdot e^8$. For the training we used $N = 1000$ iterations. $T_{train}$ denotes the training time and $T_{eval}$ the valuation time.\relax }{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Results for a one-year swing contract using transfer learning. We used 500 iterations for the aggregated contract and 300 iterations for the actual one-year contract. For the valuation, we used a sample of size $1 \cdot e^8$. $T_{agg}$ denotes the training time for the aggregated contract, $T_{train}$ and $T_{eval}$ denote respectively the training time and the valuation time for the actual contract.\relax }}{20}{table.caption.12}\protected@file@percent }
\newlabel{transfer_learning_one_year_swing}{{6}{20}{Results for a one-year swing contract using transfer learning. We used 500 iterations for the aggregated contract and 300 iterations for the actual one-year contract. For the valuation, we used a sample of size $1 \cdot e^8$. $T_{agg}$ denotes the training time for the aggregated contract, $T_{train}$ and $T_{eval}$ denote respectively the training time and the valuation time for the actual contract.\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Market data move scenarios\relax }}{20}{table.caption.13}\protected@file@percent }
\newlabel{scenario_mkt_move}{{7}{20}{Market data move scenarios\relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Results for \textit  {PV strat}. Column ``Re-use'' provides results when the baseline model parameters are reused as is. Column ``Re-train'' gives results when we re-train with only 300 iterations with the baseline model parameters used as starting values. $T_{train}$ denotes the training time and $T_{eval}$ the valuation time. The testing computation time is the same when we re-use the model as when we re-train.\relax }}{21}{table.caption.14}\protected@file@percent }
\newlabel{transfer_learning_mkt_move_strat2}{{8}{21}{Results for \textit {PV strat}. Column \q {Re-use} provides results when the baseline model parameters are reused as is. Column \q {Re-train} gives results when we re-train with only 300 iterations with the baseline model parameters used as starting values. $T_{train}$ denotes the training time and $T_{eval}$ the valuation time. The testing computation time is the same when we re-use the model as when we re-train.\relax }{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Results for \textit  {NN strat}. Column ``Re-use'' provides results when the baseline model parameters are reused as is. Column ``Re-train'' gives results when we re-train with only 300 iterations with the baseline model parameters used as starting values. $T_{train}$ denotes the training time and $T_{eval}$ the valuation time. The testing computation time is the same when we re-use the model as when we re-train.\relax }}{21}{table.caption.15}\protected@file@percent }
\newlabel{transfer_learning_mkt_move_strat3}{{9}{21}{Results for \textit {NN strat}. Column \q {Re-use} provides results when the baseline model parameters are reused as is. Column \q {Re-train} gives results when we re-train with only 300 iterations with the baseline model parameters used as starting values. $T_{train}$ denotes the training time and $T_{eval}$ the valuation time. The testing computation time is the same when we re-use the model as when we re-train.\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Numerical experiments}{21}{section.4}\protected@file@percent }
\newlabel{sec5}{{4}{21}{Numerical experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Three factor model}{21}{subsection.4.1}\protected@file@percent }
\newlabel{3fac_diff}{{4.1}{22}{Three factor model}{equation.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Results using \textit  {PV strat}. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $1 \cdot e^8$. For each result, the execution time (training plus testing) is roughly equal to 22s.\relax }}{22}{table.caption.16}\protected@file@percent }
\newlabel{three_factor_model_results_strat1}{{10}{22}{Results using \textit {PV strat}. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $1 \cdot e^8$. For each result, the execution time (training plus testing) is roughly equal to 22s.\relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Results using \textit  {NN strat}. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $1 \cdot e^8$. For the neural network architecture we used $I = 2$ layers with $q_1 = q_2 = 10$ units. For each result, the execution time (training plus testing) is roughly equal to 45s.\relax }}{22}{table.caption.17}\protected@file@percent }
\newlabel{three_factor_model_results_strat2}{{11}{22}{Results using \textit {NN strat}. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $1 \cdot e^8$. For the neural network architecture we used $I = 2$ layers with $q_1 = q_2 = 10$ units. For each result, the execution time (training plus testing) is roughly equal to 45s.\relax }{table.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Results using \textit  {NN strat} including state variables. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $1 \cdot e^8$. For the neural network architecture we used $I = 2$ layers with $q_1 = q_2 = 10$ units. For each result, the execution time (training plus testing) is roughly equal to 50s.\relax }}{23}{table.caption.18}\protected@file@percent }
\newlabel{three_factor_model_results_strat2_state_var}{{12}{23}{Results using \textit {NN strat} including state variables. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $1 \cdot e^8$. For the neural network architecture we used $I = 2$ layers with $q_1 = q_2 = 10$ units. For each result, the execution time (training plus testing) is roughly equal to 50s.\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Multi-curve forward diffusion}{23}{subsection.4.2}\protected@file@percent }
\newlabel{BGM}{{4.2}{23}{Multi-curve forward diffusion}{equation.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Square of instantaneous volatility per risk factor observed on 17-March-2021. Values are: $\leavevmode@ifvmode {\setbox \z@ \hbox {\mathsurround \z@ $\nulldelimiterspace \z@ \left (\vcenter to\@ne \big@size {}\right .$}\box \z@ }45.09\%,44.88\%,42.63\%,40.57\%,36.99\%,34.37\%,31.18\%,29.59\%,30.22\%,30.6\%,31.05\%,30.25\%\leavevmode@ifvmode {\setbox \z@ \hbox {\mathsurround \z@ $\nulldelimiterspace \z@ \left )\vcenter to\@ne \big@size {}\right .$}\box \z@ }$\relax }}{24}{figure.caption.19}\protected@file@percent }
\newlabel{vol_curve_bgm}{{6}{24}{Square of instantaneous volatility per risk factor observed on 17-March-2021. Values are: $\big (45.09\%,44.88\%,42.63\%,40.57\%,36.99\%,34.37\%,31.18\%,29.59\%,30.22\%,30.6\%,31.05\%,30.25\%\big )$\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Forward prices per risk factor observed on 17-March-2021. Prices per risk factor are: $\leavevmode@ifvmode {\setbox \z@ \hbox {\mathsurround \z@ $\nulldelimiterspace \z@ \left (\vcenter to\@ne \big@size {}\right .$}\box \z@ }20.07,20,19.6,17.4,16.75,16.5,16.56,16.53,16.71,17.31,18.31,18.64\leavevmode@ifvmode {\setbox \z@ \hbox {\mathsurround \z@ $\nulldelimiterspace \z@ \left )\vcenter to\@ne \big@size {}\right .$}\box \z@ }$\relax }}{24}{figure.caption.20}\protected@file@percent }
\newlabel{f0_curve_bgm}{{7}{24}{Forward prices per risk factor observed on 17-March-2021. Prices per risk factor are: $\big (20.07,20,19.6,17.4,16.75,16.5,16.56,16.53,16.71,17.31,18.31,18.64\big )$\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Results using \textit  {NN strat}. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $5 \times 1\cdot e^{6}$. For the neural network architecture we used $I = 2$ layers with $q_1 = q_2 = 50$ units.\relax }}{25}{table.caption.21}\protected@file@percent }
\newlabel{bgm_strat2_state_var}{{13}{25}{Results using \textit {NN strat}. Values in brackets are confidence intervals (95\%). The valuation had been performed with a sample of size $5 \times 1\cdot e^{6}$. For the neural network architecture we used $I = 2$ layers with $q_1 = q_2 = 50$ units.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Swing contract decomposition}{25}{appendix.A}\protected@file@percent }
\newlabel{swing decompo}{{A}{25}{Swing contract decomposition}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}On the rate of convergence}{27}{appendix.B}\protected@file@percent }
\newlabel{sec4}{{B}{27}{On the rate of convergence}{appendix.B}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Numerical Convergence (logarithmic scale) for \textit  {PV strat}. Case 1 (left), case 2 (right)\relax }}{27}{figure.caption.24}\protected@file@percent }
\newlabel{rate_cvg1}{{8}{27}{Numerical Convergence (logarithmic scale) for \textit {PV strat}. Case 1 (left), case 2 (right)\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Numerical Convergence (logarithmic scale) \textit  {NN strat}. Case 1 (left), case 2 (right)\relax }}{27}{figure.caption.25}\protected@file@percent }
\newlabel{rate_cvg2}{{9}{27}{Numerical Convergence (logarithmic scale) \textit {NN strat}. Case 1 (left), case 2 (right)\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Estimator variance and computation time}{27}{appendix.C}\protected@file@percent }
\newlabel{add_res}{{C}{27}{Estimator variance and computation time}{appendix.C}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Distribution of swing prices using \textit  {PV strat}. From left to right we used successively $10^{5}, 10^{6}, 10^{7}, 5 \times 10^{8}$ simulations.\relax }}{28}{figure.caption.26}\protected@file@percent }
\newlabel{var_hist_ep}{{10}{28}{Distribution of swing prices using \textit {PV strat}. From left to right we used successively $10^{5}, 10^{6}, 10^{7}, 5 \times 10^{8}$ simulations.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Distribution of swing prices using \textit  {NN strat}. From left to right we used successively $10^{5}, 10^{6}, 10^{7}, 5 \times 10^{8}$ simulations.\relax }}{28}{figure.caption.27}\protected@file@percent }
\newlabel{var_hist_nn}{{11}{28}{Distribution of swing prices using \textit {NN strat}. From left to right we used successively $10^{5}, 10^{6}, 10^{7}, 5 \times 10^{8}$ simulations.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Distribution of swing prices using Longstaff-Schwartz method. From left to right we used successively $10^{5}, 10^{6}$ simulations. Higher number of simulations leads to memory overflow.\relax }}{28}{figure.caption.28}\protected@file@percent }
\newlabel{var_hist_ls}{{12}{28}{Distribution of swing prices using Longstaff-Schwartz method. From left to right we used successively $10^{5}, 10^{6}$ simulations. Higher number of simulations leads to memory overflow.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces CPU time (in seconds) as a function of the number of iterations.\relax }}{29}{figure.caption.29}\protected@file@percent }
\newlabel{cpu_time}{{13}{29}{CPU time (in seconds) as a function of the number of iterations.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}\textit  {PV strat} coefficients}{29}{appendix.D}\protected@file@percent }
\newlabel{coeff_explicit_param}{{D}{29}{\textit {PV strat} coefficients}{appendix.D}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Coefficients of \textit  {PV strat} using PSGLD updating.\relax }}{29}{figure.caption.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Coefficients of \textit  {PV strat} using Adam updating.\relax }}{30}{figure.caption.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {E}Summary tables: Adam versus PSGLD}{30}{appendix.E}\protected@file@percent }
\newlabel{summary_table_algo}{{E}{30}{Summary tables: Adam versus PSGLD}{appendix.E}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Summary table for \textit  {PV strat} using Adam. The values in brackets are confidence intervals (95\%). The column ``time'' includes both training and valuation time.\relax }}{30}{table.caption.32}\protected@file@percent }
\newlabel{results_explicit_param}{{14}{30}{Summary table for \textit {PV strat} using Adam. The values in brackets are confidence intervals (95\%). The column \q {time} includes both training and valuation time.\relax }{table.caption.32}{}}
\bibstyle{plain}
\bibdata{biblio.bib}
\bibcite{Bardou2007WhenAS}{{1}{}{{}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Summary table for \textit  {NN strat} using Adam. We used a neural network architecture as follows: 2 hidden layers ($I = 2$) and 10 units per layer ($q_1 = 10, q_2 = 10$). The values in brackets are confidence intervals (95\%). The time includes the training and the valuation time.\relax }}{31}{table.caption.33}\protected@file@percent }
\newlabel{results_nn_param_1}{{15}{31}{Summary table for \textit {NN strat} using Adam. We used a neural network architecture as follows: 2 hidden layers ($I = 2$) and 10 units per layer ($q_1 = 10, q_2 = 10$). The values in brackets are confidence intervals (95\%). The time includes the training and the valuation time.\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Summary table for \textit  {PV strat} using PSGLD. The values in brackets are confidence intervals (95\%). The column ``time'' includes both training and valuation time. We used a learning rate equal to 0.1, one batch of size $2^{14}$, $\lambda = 1 \cdot e^{-10}$ and 1000 iterations.\relax }}{31}{table.caption.34}\protected@file@percent }
\newlabel{results_psgld_explicit_param}{{16}{31}{Summary table for \textit {PV strat} using PSGLD. The values in brackets are confidence intervals (95\%). The column \q {time} includes both training and valuation time. We used a learning rate equal to 0.1, one batch of size $2^{14}$, $\lambda = 1 \cdot e^{-10}$ and 1000 iterations.\relax }{table.caption.34}{}}
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Summary table for \textit  {NN strat} using PSGLD. We used $I = 2$ layers with $q_1 = q_2 = 10$ units. The values in brackets are confidence intervals (95\%). The column ``time'' includes both training and valuation time. We used a learning rate equal to 0.1, one batch of size $2^{14}$, $\lambda = 1 \cdot e^{-10}$ and 1000 iterations.\relax }}{31}{table.caption.35}\protected@file@percent }
\newlabel{results_psgld_nn_param}{{17}{31}{Summary table for \textit {NN strat} using PSGLD. We used $I = 2$ layers with $q_1 = q_2 = 10$ units. The values in brackets are confidence intervals (95\%). The column \q {time} includes both training and valuation time. We used a learning rate equal to 0.1, one batch of size $2^{14}$, $\lambda = 1 \cdot e^{-10}$ and 1000 iterations.\relax }{table.caption.35}{}}
\bibcite{Bardou2009OptimalQF}{{2}{}{{}}{{}}}
\bibcite{BarreraEsteve2006NumericalMF}{{3}{}{{}}{{}}}
\bibcite{Baydin2017AutomaticDI}{{4}{}{{}}{{}}}
\bibcite{EonBottou1998OnlineLA}{{5}{}{{}}{{}}}
\bibcite{bras2022langevin}{{6}{}{{}}{{}}}
\bibcite{bras:hal-03891234}{{7}{}{{}}{{}}}
\bibcite{PierreLangevin}{{8}{}{{}}{{}}}
\bibcite{Broadie2004ASM}{{9}{}{{}}{{}}}
\bibcite{pmlr-v84-chee18a}{{10}{}{{}}{{}}}
\bibcite{Dalalyan2014TheoreticalGF}{{11}{}{{}}{{}}}
\bibcite{Dalalyan2017FurtherAS}{{12}{}{{}}{{}}}
\bibcite{Dauphin2014IdentifyingAA}{{13}{}{{}}{{}}}
\bibcite{Defossez2020ASC}{{14}{}{{}}{{}}}
\bibcite{langcvg}{{15}{}{{}}{{}}}
\bibcite{durmus2018highdimensional}{{16}{}{{}}{{}}}
\bibcite{GobetMunos}{{17}{}{{}}{{}}}
\bibcite{Hornik1989MultilayerFN}{{18}{}{{}}{{}}}
\bibcite{Jaillet1990VariationalIA}{{19}{}{{}}{{}}}
\bibcite{Jaillet2004ValuationOC}{{20}{}{{}}{{}}}
\bibcite{Jospin_2022}{{21}{}{{}}{{}}}
\bibcite{Kingma2015AdamAM}{{22}{}{{}}{{}}}
\bibcite{Kushner2003StochasticAA}{{23}{}{{}}{{}}}
\bibcite{LariLavassani2002ADV}{{24}{}{{}}{{}}}
\bibcite{Li2016PreconditionedSG}{{25}{}{{}}{{}}}
\bibcite{sgdSaddlePoints}{{26}{}{{}}{{}}}
\bibcite{Longstaff2001ValuingAO}{{27}{}{{}}{{}}}
\bibcite{addgaussnoise}{{28}{}{{}}{{}}}
\bibcite{Pags2020UnadjustedLA}{{29}{}{{}}{{}}}
\bibcite{Pags2004OptimalQM}{{30}{}{{}}{{}}}
\bibcite{Pan2010ASO}{{31}{}{{}}{{}}}
\bibcite{Paszke2017AutomaticDI}{{32}{}{{}}{{}}}
\bibcite{sgdMoment}{{33}{}{{}}{{}}}
\bibcite{Robbins2007ASA}{{34}{}{{}}{{}}}
\bibcite{Robbins1971ACT}{{35}{}{{}}{{}}}
\bibcite{Rogers2002MonteCV}{{36}{}{{}}{{}}}
\bibcite{Rumelhart1986LearningIR}{{37}{}{{}}{{}}}
\bibcite{Thompson1995ValuationOP}{{38}{}{{}}{{}}}
\bibcite{Welling2011BayesianLV}{{39}{}{{}}{{}}}
\bibcite{Zou2018ASC}{{40}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{33}
