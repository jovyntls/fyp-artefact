\documentclass[pmlr]{jmlr}% new name PMLR (Proceedings of Machine Learning)

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\usepackage{rotating}% for sideways figures and tables
%\usepackage{longtable}% for long tables

 % The booktabs package is used by this sample document
 % (it provides \toprule, \midrule and \bottomrule).
 % 
 % book quality tables
 \usepackage{booktabs}
 \usepackage{wrapfig}
 
 % The siunitx package is used by this sample document
 % to align numbers in a column by their decimal point.
 % Remove the next line if you don't require it.
\usepackage[load-configurations=version-1]{siunitx} % newer version
 %\usepackage{siunitx}

%hz added package
\usepackage{enumitem}
\usepackage{float}

% Avoid annoying warnings that come with some pdf figures
\makeatletter
\def\set@curr@file#1{\def\@curr@file{#1}} %temp workaround for 2019 latex release
\makeatother

\newcommand{\todo}[1]{{\color{red} #1}}
\newcommand{\mch}[1]{{\color{orange} #1}}

% change the arguments, as appropriate, in the following:
\jmlrvolume{}
\jmlryear{2023}
\jmlrworkshop{} %Machine Learning for Healthcare}

\firstpageno{1}
\usepackage{titletoc}
\usepackage{titlesec}

%%% MCH SPACE-REDUCING HACK 1/3
% Small captions
\usepackage{subcaption}
\captionsetup[table]{font=small,labelfont=small}
\captionsetup[figure]{font=small,labelfont=small}

%%%% MCH SPACE-REDUCING HACK 2/3
%% Reduce spacing around floats 
\setlength{\floatsep}{8pt plus 4pt minus 4pt}
\setlength{\textfloatsep}{8pt plus 4pt minus 3pt}

\title[Detecting Heart Disease from Multi-View Ultrasound via SAMIL]{Detecting Heart Disease from Multi-View Ultrasound Images via Supervised Attention Multiple Instance Learning}
%\title[Short Title]{Prior Guided Attention-Based Multiple Instance Learning with Self-supervised Patient Representation Learning to Detect Heart Disease in Multi-View Ultrasound Images}

\author{\Name{Zhe Huang}$^{1}$
		\Email{\textsc{zhe.huang@tufts.edu}}
\AND
        \Name{Benjamin S. Wessler}$^{2}$
		\Email{\textsc{bwessler@tuftsmedicalcenter.org}}
\AND       
        \Name{Michael C. Hughes}$^1$
        \Email{\textsc{michael.hughes@tufts.edu}}
        \\
        \addr $^1$ Dept. of Computer Science, Tufts University, Medford, MA, USA
        \\
        \addr $^2$ Division of Cardiology, Tufts Medical Center, Boston, MA, USA
}%endauthortag



\begin{document}
%%% MCH SPACE-REDUCING HACK 3/3
% Reset vertical space for equations 
% (must be after \begin{document})
\setlength{\abovedisplayskip}{2pt plus 3pt}
\setlength{\belowdisplayskip}{2pt plus 3pt}

\maketitle

\begin{abstract}
  \input{abstract.tex}
\end{abstract}
\let\thefootnote\relax\footnotetext{Open-source Code for our Supervised Attention MIL (SAMIL): \url{https://github.com/tufts-ml/SAMIL}}

\startcontents[sections]

\section{Introduction}
\label{sec:Introduction}
\input{intro.tex}


\section{Related Work}
\label{sec:RelatedWork}
\input{related_work.tex}

\section{Dataset}
\label{sec:Dataset}
\input{dataset.tex}


\section{Methods}
We now introduce our formulation of AS diagnosis as an MIL problem in Sec~\ref{sec:methods_formulation} and
discuss a general architecture for MIL (Sec.~\ref{sec:base_arch}).
We then present the two key innovations of our proposed method, which we call \emph{Supervised Attention Multiple Instance Learning} or SAMIL.
First, Sec.~\ref{sec:methods_SA} presents our supervised attention module that improves the MIL pooling layer to better attend to clinically relevant views.
Second, Sec.~\ref{sec:methods_CL} presents our study-level contrastive learning strategy to improve representation of entire studies (rather than individual images). Fig~\ref{fig:workflow_diagram} gives an overview of SAMIL.
%%Our proposed method is most similar to ABMIL, with two key components: A view regularization module that regularized the attention weights to align with the predicted view relevance, and a novel pretraining strategy that performs 'study-discrimination' instead of 'instance-discrimination'. 


\input{fig2_workflow_diagram}
\label{sec:Methods}
\input{methods.tex}


\section{Results} 
\label{sec:Results}
\input{results.tex}
 
\section{Discussion} 
\label{sec:Discussion}
\input{discussion.tex}



% ACKNOWLEDGEMENTS ONLY GO IN THE CAMERA-READY, NOT THE SUBMISSION
\acks{
We acknowledge financial support from the Pilot Studies Program at the Tufts Clinical and Translational Science Institute (Tufts CTSI NIH CTSA UL1TR002544). We are grateful for computing infrastructure support from the Tufts High-performance Computing cluster, partially funded by the National Science Foundation under grant OAC CC* 2018149.
Author B. W. was supported in part by K23AG055667 (NIH-NIA).
}

\begin{small}
\bibliography{refs_manual.bib}    
\end{small}

\appendix

%% Config Table-of-Contents to track the sections of the appendix
\startcontents[sections]

\counterwithin{table}{section}
\setcounter{table}{0}
\counterwithin{figure}{section}
\setcounter{figure}{0}
%\counterwithin{algorithm}{section}
%\setcounter{algorithm}{0}

%% Use ONE counter for all figs and tables to give unique identifiers in supplement
\makeatletter 
\let\c@table\c@figure
\let\c@lstlisting\c@figure
\let\c@algorithm\c@figure
\makeatother

% Print Table of Contents
\subsection*{Appendix Contents}
\printcontents[sections]{l}{1}{\setcounter{tocdepth}{2}}

\section{Further Results}
\subsection{Confusion matrix}
\input{fig_confusion_mat.tex}

\subsection{ROC for AS Screening Tasks}
\input{fig_TMED2_ROC.tex}

\subsection{Attended Images by SAMIL and ABMIL}
\input{fig_AttendedImages}

\section{Methods Supplement}
\subsection{Architecture}
\label{app:Architecture}
\input{app_Architecture}

\subsection{View Classifier}
\label{app:ViewClassifier}
\input{app_ViewClassifier}

\section{MIL Experiment Details}
\input{app_experiment_details}

\section{Self-supervised Pretraining}
\label{app:SSL_Pretraining}
\input{app_SSL_Pretraining}

\section{Additional Related Work}
\label{app:relatedworks}
\input{app_relatedworks}



\end{document}
