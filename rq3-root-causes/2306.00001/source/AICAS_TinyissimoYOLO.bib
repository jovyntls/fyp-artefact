
@article{zhu_prune_2017,
	title = {To prune, or not to prune: exploring the efficacy of pruning for model compression},
	shorttitle = {To prune, or not to prune},
	abstract = {Model pruning seeks to induce sparsity in a deep neural network's various connection matrices, thereby reducing the number of nonzero-valued parameters in the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep networks at the cost of only a marginal loss in accuracy and achieve a sizable reduction in model size. This hints at the possibility that the baseline models in these experiments are perhaps severely over-parameterized at the outset and a viable alternative for model compression might be to simply reduce the number of hidden units while maintaining the model's dense connection structure, exposing a similar trade-off in model size and accuracy. We investigate these two distinct paths for model compression within the context of energy-efficient inference in resource-constrained environments and propose a new gradual pruning technique that is simple and straightforward to apply across a variety of models/datasets with minimal tuning and can be seamlessly incorporated within the training process. We compare the accuracy of large, but pruned models (large-sparse) and their smaller, but dense (small-dense) counterparts with identical memory footprint. Across a broad range of neural network architectures (deep {CNNs}, stacked {LSTM}, and seq2seq {LSTM} models), we find large-sparse models to consistently outperform small-dense models and achieve up to 10x reduction in number of non-zero parameters with minimal loss in accuracy.},
	journaltitle = {{arXiv}:1710.01878 [cs, stat]},
	author = {Zhu, Michael and Gupta, Suyog},
	urldate = {2021-09-29},
	date = {2017-11-13},
	eprinttype = {arxiv},
	eprint = {1710.01878},
        journal={arXiv preprint arXiv:1710.01878},
        year={2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/PH2FNJZL/Zhu and Gupta - 2017 - To prune, or not to prune exploring the efficacy .pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/F6GJKZ2T/1710.html:text/html},
	url = {http://arxiv.org/abs/1710.01878},
}

@article{han_deep_2016,
	title = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
	shorttitle = {Deep Compression},
	abstract = {Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce "deep compression", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the {ImageNet} dataset, our method reduced the storage required by {AlexNet} by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of {VGG}-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip {SRAM} cache rather than off-chip {DRAM} memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on {CPU}, {GPU} and mobile {GPU}, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.},
	journaltitle = {{arXiv}:1510.00149 [cs]},
	author = {Han, Song and Mao, Huizi and Dally, William J.},
	urldate = {2021-09-28},
	date = {2016-02-15},
	eprinttype = {arxiv},
	eprint = {1510.00149},
        journal={arXiv preprint arXiv:1510.00149},
        year={2015},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/7AHFPRWL/Han et al. - 2016 - Deep Compression Compressing Deep Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/JIDY8VQ7/1510.html:text/html},
	url = {http://arxiv.org/abs/1510.00149},
}

@article{lin_mcunetv2_2021,
	title = {{MCUNetV}2: Memory-Efficient Patch-based Inference for Tiny Deep Learning},
	shorttitle = {{MCUNetV}2},
	abstract = {Tiny deep learning on microcontroller units ({MCUs}) is challenging due to the limited memory size. We find that the memory bottleneck is due to the imbalanced memory distribution in convolutional neural network ({CNN}) designs: the first several blocks have an order of magnitude larger memory usage than the rest of the network. To alleviate this issue, we propose a generic patch-by-patch inference scheduling, which operates only on a small spatial region of the feature map and significantly cuts down the peak memory. However, naive implementation brings overlapping patches and computation overhead. We further propose network redistribution to shift the receptive field and {FLOPs} to the later stage and reduce the computation overhead. Manually redistributing the receptive field is difficult. We automate the process with neural architecture search to jointly optimize the neural architecture and inference scheduling, leading to {MCUNetV}2. Patch-based inference effectively reduces the peak memory usage of existing networks by 4-8x. Co-designed with neural networks, {MCUNetV}2 sets a record {ImageNet} accuracy on {MCU} (71.8\%), and achieves {\textgreater}90\% accuracy on the visual wake words dataset under only 32kB {SRAM}. {MCUNetV}2 also unblocks object detection on tiny devices, achieving 16.9\% higher {mAP} on Pascal {VOC} compared to the state-of-the-art result. Our study largely addressed the memory bottleneck in {tinyML} and paved the way for various vision applications beyond image classification.},
	journaltitle = {{arXiv}:2110.15352 [cs]},
	author = {Lin, Ji and Chen, Wei-Ming and Cai, Han and Gan, Chuang and Han, Song},
	urldate = {2022-05-09},
        journal={arXiv preprint arXiv:2110.15352},
        year = {2021},
	date = {2021-10-28},
	eprinttype = {arxiv},
	eprint = {2110.15352},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/SJ47288T/Lin et al. - 2021 - MCUNetV2 Memory-Efficient Patch-based Inference f.pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/TBINYCJA/2110.html:text/html},
	url = {http://arxiv.org/abs/2110.15352},
}

@article{cai_once-for-all_2020,
	title = {Once-for-All: Train One Network and Specialize it for Efficient Deployment},
	shorttitle = {Once-for-All},
	abstract = {We address the challenging problem of efficient inference across many devices and resource constraints, especially on edge devices. Conventional approaches either manually design or use neural architecture search ({NAS}) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing \${CO}\_2\$ emission as much as 5 cars' lifetime) thus unscalable. In this work, we propose to train a once-for-all ({OFA}) network that supports diverse architectural settings by decoupling training and search, to reduce the cost. We can quickly get a specialized sub-network by selecting from the {OFA} network without additional training. To efficiently train {OFA} networks, we also propose a novel progressive shrinking algorithm, a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution). It can obtain a surprisingly large number of sub-networks (\${\textgreater} 10{\textasciicircum}\{19\}\$) that can fit different hardware platforms and latency constraints while maintaining the same level of accuracy as training independently. On diverse edge devices, {OFA} consistently outperforms state-of-the-art ({SOTA}) {NAS} methods (up to 4.0\% {ImageNet} top1 accuracy improvement over {MobileNetV}3, or same accuracy but 1.5x faster than {MobileNetV}3, 2.6x faster than {EfficientNet} w.r.t measured latency) while reducing many orders of magnitude {GPU} hours and \${CO}\_2\$ emission. In particular, {OFA} achieves a new {SOTA} 80.0\% {ImageNet} top-1 accuracy under the mobile setting (\${\textless}\$600M {MACs}). {OFA} is the winning solution for the 3rd Low Power Computer Vision Challenge ({LPCVC}), {DSP} classification track and the 4th {LPCVC}, both classification track and detection track. Code and 50 pre-trained models (for many devices \& many latency constraints) are released at https://github.com/mit-han-lab/once-for-all.},
	journaltitle = {{arXiv}:1908.09791 [cs, stat]},
	author = {Cai, Han and Gan, Chuang and Wang, Tianzhe and Zhang, Zhekai and Han, Song},
	urldate = {2022-01-25},
	date = {2020-04-29},
	eprinttype = {arxiv},
	eprint = {1908.09791},
        journal={arXiv preprint arXiv:1908.09791},
        year={2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/8NWW8RN4/Cai et al. - 2020 - Once-for-All Train One Network and Specialize it .pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/FBIIS3ZP/1908.html:text/html},
	url = {http://arxiv.org/abs/1908.09791},
}

@inproceedings{liu_ssd_2016,
	location = {Cham},
	title = {{SSD}: Single Shot {MultiBox} Detector},
	isbn = {978-3-319-46448-0},
	doi = {10.1007/978-3-319-46448-0_2},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SSD}},
	abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named {SSD}, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. {SSD} is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes {SSD} easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the {PASCAL} {VOC}, {COCO}, and {ILSVRC} datasets confirm that {SSD} has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For 300×300300×300300 {\textbackslash}times 300 input, {SSD} achieves 74.3 \% {mAP} on {VOC}2007 test at 59 {FPS} on a Nvidia Titan X and for 512×512512×512512 {\textbackslash}times 512 input, {SSD} achieves 76.9 \% {mAP}, outperforming a comparable state of the art Faster R-{CNN} model. Compared to other single stage methods, {SSD} has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.},
	pages = {21--37},
	booktitle = {Computer Vision – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	langid = {english},
	keywords = {Convolutional neural network, Real-time object detection},
	file = {Springer Full Text PDF:/Users/mojulian/Zotero/storage/742RHQ4X/Liu et al. - 2016 - SSD Single Shot MultiBox Detector.pdf:application/pdf},
}

@article{lin_mcunet_2020,
	title = {{MCUNet}: Tiny Deep Learning on {IoT} Devices},
	shorttitle = {{MCUNet}},
	abstract = {Machine learning on tiny {IoT} devices based on microcontroller units ({MCU}) is appealing but challenging: the memory of microcontrollers is 2-3 orders of magnitude smaller even than mobile phones. We propose {MCUNet}, a framework that jointly designs the efficient neural architecture ({TinyNAS}) and the lightweight inference engine ({TinyEngine}), enabling {ImageNet}-scale inference on microcontrollers. {TinyNAS} adopts a two-stage neural architecture search approach that first optimizes the search space to fit the resource constraints, then specializes the network architecture in the optimized search space. {TinyNAS} can automatically handle diverse constraints (i.e.device, latency, energy, memory) under low search costs.{TinyNAS} is co-designed with {TinyEngine}, a memory-efficient inference library to expand the search space and fit a larger model. {TinyEngine} adapts the memory scheduling according to the overall network topology rather than layer-wise optimization, reducing the memory usage by 4.8x, and accelerating the inference by 1.7-3.3x compared to {TF}-Lite Micro and {CMSIS}-{NN}. {MCUNet} is the first to achieves {\textgreater}70\% {ImageNet} top1 accuracy on an off-the-shelf commercial microcontroller, using 3.5x less {SRAM} and 5.7x less Flash compared to quantized {MobileNetV}2 and {ResNet}-18. On visual\&audio wake words tasks, {MCUNet} achieves state-of-the-art accuracy and runs 2.4-3.4x faster than {MobileNetV}2 and {ProxylessNAS}-based solutions with 3.7-4.1x smaller peak {SRAM}. Our study suggests that the era of always-on tiny machine learning on {IoT} devices has arrived. Code and models can be found here: https://tinyml.mit.edu.},
	journaltitle = {{arXiv}:2007.10319 [cs]},
	author = {Lin, Ji and Chen, Wei-Ming and Lin, Yujun and Cohn, John and Gan, Chuang and Han, Song},
	urldate = {2021-11-22},
	date = {2020-11-19},
	eprinttype = {arxiv},
	eprint = {2007.10319},
        journal={Advances in Neural Information Processing Systems},
        year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/6GCQUR7T/Lin et al. - 2020 - MCUNet Tiny Deep Learning on IoT Devices.pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/PS56ZA47/2007.html:text/html},
	url = {http://arxiv.org/abs/2007.10319},
}


@inproceedings{boner2022tiny,
  title={Tiny TCN model for Gesture Recognition With Multi-point Low power ToF-Sensors},
  author={Boner, Stephan and Vogt, Christian and Magno, Michele},
  booktitle={2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)},
  pages={356--359},
  year={2022},
  organization={IEEE},
  url={},
}

@article{wang2020fann,
  title={FANN-on-MCU: An open-source toolkit for energy-efficient neural network inference at the edge of the Internet of Things},
  author={Wang, Xiaying and Magno, Michele and Cavigelli, Lukas and Benini, Luca},
  journal={IEEE Internet of Things Journal},
  volume={7},
  number={5},
  pages={4403--4417},
  year={2020},
  publisher={IEEE},
  url={},
}

@article{scherer2021tinyradarnn,
  title={Tinyradarnn: Combining spatial and temporal convolutional neural networks for embedded gesture recognition with short range radars},
  author={Scherer, Moritz and Magno, Michele and Erb, Jonas and Mayer, Philipp and Eggimann, Manuel and Benini, Luca},
  journal={IEEE Internet of Things Journal},
  volume={8},
  number={13},
  pages={10336--10346},
  year={2021},
  publisher={IEEE},
  url={},
}

@inproceedings{ren_faster_2015,
	title = {Faster R-{CNN}: Towards Real-Time Object Detection with Region Proposal Networks},
	volume = {28},
	shorttitle = {Faster R-{CNN}},
	abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like {SPPnet} and Fast R-{CNN} have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network ({RPN}) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An {RPN} is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. {RPNs} are trained end-to-end to generate high-quality region proposals, which are used by Fast R-{CNN} for detection. With a simple alternating optimization, {RPN} and Fast R-{CNN} can be trained to share convolutional features. For the very deep {VGG}-16 model, our detection system has a frame rate of 5fps (including all steps) on a {GPU}, while achieving state-of-the-art object detection accuracy on {PASCAL} {VOC} 2007 (73.2\% {mAP}) and 2012 (70.4\% {mAP}) using 300 proposals per image. Code is available at https://github.com/{ShaoqingRen}/faster\_rcnn.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	urldate = {2023-01-23},
	date = {2015},
        year={2015},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/S8DJM48M/Ren et al. - 2015 - Faster R-CNN Towards Real-Time Object Detection w.pdf:application/pdf},
	url = {},
}

@misc{molchanov_pruning_2017,
	title = {Pruning Convolutional Neural Networks for Resource Efficient Inference},
	doi = {10.48550/arXiv.1611.06440},
	abstract = {We propose a new formulation for pruning convolutional kernels in neural networks to enable efficient inference. We interleave greedy criteria-based pruning with fine-tuning by backpropagation - a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on Taylor expansion that approximates the change in the cost function induced by pruning network parameters. We focus on transfer learning, where large pretrained networks are adapted to specialized tasks. The proposed criterion demonstrates superior performance compared to other criteria, e.g. the norm of kernel weights or feature map activation, for pruning large {CNNs} after adaptation to fine-grained classification tasks (Birds-200 and Flowers-102) relaying only on the first order gradient information. We also show that pruning can lead to more than 10x theoretical (5x practical) reduction in adapted 3D-convolutional filters with a small drop in accuracy in a recurrent gesture classifier. Finally, we show results for the large-scale {ImageNet} dataset to emphasize the flexibility of our approach.},
	number = {{arXiv}:1611.06440},
	publisher = {{arXiv}},
	author = {Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
	urldate = {2023-01-23},
	date = {2017-06-08},
	eprinttype = {arxiv},
	eprint = {1611.06440 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/B8MWBTGX/Molchanov et al. - 2017 - Pruning Convolutional Neural Networks for Resource.pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/4L59FY9R/1611.html:text/html},
	url = {http://arxiv.org/abs/1611.06440},
}

@misc{gholami_survey_2021,
	title = {A Survey of Quantization Methods for Efficient Neural Network Inference},
	abstract = {As soon as abstract mathematical computations were adapted to computation on digital computers, the problem of efficient representation, manipulation, and communication of the numerical values in those computations arose. Strongly related to the problem of numerical representation is the problem of quantization: in what manner should a set of continuous real-valued numbers be distributed over a fixed discrete set of numbers to minimize the number of bits required and also to maximize the accuracy of the attendant computations? This perennial problem of quantization is particularly relevant whenever memory and/or computational resources are severely restricted, and it has come to the forefront in recent years due to the remarkable performance of Neural Network models in computer vision, natural language processing, and related areas. Moving from floating-point representations to low-precision fixed integer values represented in four bits or less holds the potential to reduce the memory footprint and latency by a factor of 16x; and, in fact, reductions of 4x to 8x are often realized in practice in these applications. Thus, it is not surprising that quantization has emerged recently as an important and very active sub-area of research in the efficient implementation of computations associated with Neural Networks. In this article, we survey approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. With this survey and its organization, we hope to have presented a useful snapshot of the current research in quantization for Neural Networks and to have given an intelligent organization to ease the evaluation of future research in this area.},
	number = {{arXiv}:2103.13630},
	publisher = {{arXiv}},
	author = {Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
	urldate = {2023-01-23},
	date = {2021-06-21},
	eprinttype = {arxiv},
	eprint = {2103.13630 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/LSQRJGYE/Gholami et al. - 2021 - A Survey of Quantization Methods for Efficient Neu.pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/Q3ERDKN9/2103.html:text/html},
	url = {http://arxiv.org/abs/2103.13630},
}

@inproceedings{li_fully_2019,
	title = {Fully Quantized Network for Object Detection},
	eventtitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	pages = {2810--2819},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	author = {Li, Rundong and Wang, Yan and Liang, Feng and Qin, Hongwei and Yan, Junjie and Fan, Rui},
	urldate = {2023-01-23},
	year = {2019},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/2A9S5Q4S/Li et al. - 2019 - Fully Quantized Network for Object Detection.pdf:application/pdf},
	url = {},
}

@inproceedings{reuther_survey_2020,
	title = {Survey of Machine Learning Accelerators},
	doi = {10.1109/HPEC43674.2020.9286149},
	abstract = {New machine learning accelerators are being announced and released each month for a variety of applications from speech recognition, video object detection, assisted driving, and many data center applications. This paper updates the survey of of {AI} accelerators and processors from last year's {IEEE}-{HPEC} paper. This paper collects and summarizes the current accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. This year, there are many more announced accelerators that are implemented with many more architectures and technologies from vector engines, dataflow engines, neuromorphic designs, flash-based analog memory processing, and photonic-based processing.},
	eventtitle = {2020 {IEEE} High Performance Extreme Computing Conference ({HPEC})},
	pages = {1--12},
	booktitle = {2020 {IEEE} High Performance Extreme Computing Conference ({HPEC})},
	author = {Reuther, Albert and Michaleas, Peter and Jones, Michael and Gadepally, Vijay and Samsi, Siddharth and Kepner, Jeremy},
	date = {2020-09},
        year={2020},
	note = {{ISSN}: 2643-1971},
	keywords = {accelerator, computational performance, dataflow, embedded inference, Engines, {GPU}, Machine learning, Market research, Power demand, Program processors, Speech recognition, {TPU}, Training},
	file = {IEEE Xplore Abstract Record:/Users/mojulian/Zotero/storage/QR24DTM2/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/mojulian/Zotero/storage/K2UAIFXK/Reuther et al. - 2020 - Survey of Machine Learning Accelerators.pdf:application/pdf},
}


@article{yousefi_intelligence_2019,
      title={The Intelligence of Things enabled by Syntiant's TinyML board},
      author={Yousefi, Alireza and Franca-Neto, Luiz and McDonald, Will and Gupta, Atul and Moturi, Mallik and Garrett, David},
	shorttitle = {Intelligence},
	abstract = {In this poster, we present our new {TinyML} development board designed for batterypowered always-on edge-{AI} applications. The board contains an {IMU} sensor for motion sensing, a {MEMS} microphone for audio applications, and a {uSD} card slot for data collection. Having an ultra-low-power {NDP}101 chip at its core, the dream of having a sub-{mW} edge-{AI} system can readily come true. {DNN} models can be trained and uploaded to the board using the Edge Impulse platform. The poster will also present two use cases for the board in which we demonstrate how to build audio and motion detection models and deploy them on the board. The board can be seen as a step toward democratizing “Tiny” machine learning.},
	urldate = {2023-01-23},
	date = {2019-09-15},
        year = {2019},
        journal = {tinyML Summit},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Statistics - Machine Learning},
	file = {Park et al. - 2019 - SpecAugment A Simple Data Augmentation Method for.pdf:/Users/mojulian/Zotero/storage/MINY6JAV/Park et al. - 2019 - SpecAugment A Simple Data Augmentation Method for.pdf:application/pdf},
	url = {},

}

@inproceedings{redmon_you_2016,
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	shorttitle = {You Only Look Once},
	eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
        booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
        year = {2016},
	pages = {779--788},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	urldate = {2023-01-23},
	date = {2016},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/W27QF64F/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf},
        url = {}
}

@inproceedings{yang_wider_2016,
	title = {{WIDER} {FACE}: A Face Detection Benchmark},
	shorttitle = {{WIDER} {FACE}},
	booktitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {5525--5533},
	author = {Yang, Shuo and Luo, Ping and Loy, Chen-Change and Tang, Xiaoou},
	urldate = {2023-01-23},
	year = {2016},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/97Q5MRI7/Yang et al. - 2016 - WIDER FACE A Face Detection Benchmark.pdf:application/pdf},
	url = {},
}

@article{everingham_pascal_2015,
	title = {The Pascal Visual Object Classes Challenge: A Retrospective},
	volume = {111},
	issn = {1573-1405},
	doi = {10.1007/s11263-014-0733-5},
	shorttitle = {The Pascal Visual Object Classes Challenge},
	abstract = {The Pascal Visual Object Classes ({VOC}) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008–2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the {VOC} datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the {VOC} datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community’s progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.},
	pages = {98--136},
	number = {1},
	journaltitle = {Int J Comput Vis},
        journal={International journal of computer vision},
	author = {Everingham, Mark and Eslami, S. M. Ali and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	urldate = {2023-01-23},
	date = {2015-01-01},
	langid = {english},
        year = {2015},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/38MP7X9C/Everingham et al. - 2015 - The Pascal Visual Object Classes Challenge A Retr.pdf:application/pdf},
	url = {https://doi.org/10.1007/s11263-014-0733-5},
}

@article{david_tensorflow_2021,
	title = {{TensorFlow} Lite Micro: Embedded Machine Learning for {TinyML} Systems},
	volume = {3},
	shorttitle = {{TensorFlow} Lite Micro},
	pages = {800--811},
        journal={Proceedings of Machine Learning and Systems},
        year={2021},
	journaltitle = {Proceedings of Machine Learning and Systems},
	author = {David, Robert and Duke, Jared and Jain, Advait and Janapa Reddi, Vijay and Jeffries, Nat and Li, Jian and Kreeger, Nick and Nappier, Ian and Natraj, Meghna and Wang, Tiezhen and Warden, Pete and Rhodes, Rocky},
	urldate = {2023-01-23},
	date = {2021-03-15},
	langid = {english},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/N25Z8A7L/David et al. - 2021 - TensorFlow Lite Micro Embedded Machine Learning f.pdf:application/pdf},
	url = {},
}

@inproceedings{giordano_survey_2022,
	title = {Survey and Comparison of Milliwatts Micro controllers for Tiny Machine Learning at the Edge},
	doi = {10.1109/AICAS54282.2022.9870017},
	abstract = {Low power Internet of Things devices are growing in number and computational capabilities, pushing to ubiquitous deployment of smart sensors that embed on board both the sensing and the processing. Thus, one of the most emerging requirements of such devices is to provide intelligence in resource-constrained processors that consume few milliwatts of power. This work focuses on surveying, comparing and evaluating seven different recent and popular microcontrollers with a power envelope from a few up to hundreds of milliwatts against a Convolutional Neural Networks workload for a non trivial task such as face recognition. The evaluation reports key points of tiny machine learning performance of the target microcontrollers in terms of inference time, power consumption, energy per inference and computational efficiency. Experimental results highlight best-in-class power consumption for Ambiq Apollo3 and Sony Spresense at 41.3 μW/{MHz} and 128.2 μW/{MHz} respectively. The computational efficiency primacy goes instead to the {MAX}78000 and then to {xCORE}.ai at 117 {MAC}/cycle and 7.69 {MAC}/cycle respectively, achieving the fastest inference at 1.4 ms and 1.5 ms respectively. The platforms that required the least energy per inference were the {MAX}78000 and {GAP}8, at 0.09 {mJ}/inference and 0.52 {mJ}/inference respectively. The benchmarked {tinyML} network will be released openly to allow other researchers to run future comparisons on novel low power microprocessors.},
	eventtitle = {2022 {IEEE} 4th International Conference on Artificial Intelligence Circuits and Systems ({AICAS})},
	pages = {94--97},
	booktitle = {2022 {IEEE} 4th International Conference on Artificial Intelligence Circuits and Systems ({AICAS})},
	author = {Giordano, Marco and Piccinelli, Luigi and Magno, Michele},
	date = {2022-06},
        year = {2022},
	keywords = {Benchmark, {CNN}, Comparison, Computer architecture, Low-power, Microcontrollers, Multicore processing, Parallel processing, Performance evaluation, Power demand, Program processors, Survey, {TinyML}},
	file = {IEEE Xplore Abstract Record:/Users/mojulian/Zotero/storage/7SL8Y358/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/mojulian/Zotero/storage/VLZDBCFQ/Giordano et al. - 2022 - Survey and Comparison of Milliwatts Micro controll.pdf:application/pdf},
}

@incollection{saad_-line_1999,
	edition = {1},
	title = {On-line Learning and Stochastic Approximations},
	isbn = {978-0-521-65263-6 978-0-521-11791-3 978-0-511-56992-0},
	abstract = {The convergence of online learning algorithms is analyzed using the tools of the stochastic approximation theory, and proved under very weak conditions. A general framework for online learning algorithms is ﬁrst presented. This framework encompasses the most common online learning algorithms in use today, as illustrated by several examples. The stochastic approximation theory then provides general results describing the convergence of all these learning algorithms at once.},
	pages = {9--42},
	booktitle = {On-Line Learning in Neural Networks},
	publisher = {Cambridge University Press},
	author = {Bottou, Léon},
	editor = {Saad, David},
	urldate = {2023-01-23},
	date = {1999-01-28},
        year = {1998},
	langid = {english},
	doi = {10.1017/CBO9780511569920.003},
	file = {Bottou - 1999 - On-line Learning and Stochastic Approximations.pdf:/Users/mojulian/Zotero/storage/ZX4GT99X/Bottou - 1999 - On-line Learning and Stochastic Approximations.pdf:application/pdf},
	url = {},
}

@misc{goyal_accurate_2018,
	title = {Accurate, Large Minibatch {SGD}: Training {ImageNet} in 1 Hour},
	doi = {10.48550/arXiv.1706.02677},
	shorttitle = {Accurate, Large Minibatch {SGD}},
	abstract = {Deep learning thrives with large neural networks and large datasets. However, larger networks and larger datasets result in longer training times that impede research and development progress. Distributed synchronous {SGD} offers a potential solution to this problem by dividing {SGD} minibatches over a pool of parallel workers. Yet to make this scheme efficient, the per-worker workload must be large, which implies nontrivial growth in the {SGD} minibatch size. In this paper, we empirically show that on the {ImageNet} dataset large minibatches cause optimization difficulties, but when these are addressed the trained networks exhibit good generalization. Specifically, we show no loss of accuracy when training with large minibatch sizes up to 8192 images. To achieve this result, we adopt a hyper-parameter-free linear scaling rule for adjusting learning rates as a function of minibatch size and develop a new warmup scheme that overcomes optimization challenges early in training. With these simple techniques, our Caffe2-based system trains {ResNet}-50 with a minibatch size of 8192 on 256 {GPUs} in one hour, while matching small minibatch accuracy. Using commodity hardware, our implementation achieves {\textasciitilde}90\% scaling efficiency when moving from 8 to 256 {GPUs}. Our findings enable training visual recognition models on internet-scale data with high efficiency.},
	number = {{arXiv}:1706.02677},
	publisher = {{arXiv}},
	author = {Goyal, Priya and Dollár, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
	urldate = {2023-01-23},
	date = {2018-04-30},
	eprinttype = {arxiv},
	eprint = {1706.02677 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mojulian/Zotero/storage/UTPXU4P6/Goyal et al. - 2018 - Accurate, Large Minibatch SGD Training ImageNet i.pdf:application/pdf;arXiv.org Snapshot:/Users/mojulian/Zotero/storage/7ZRIE3SS/1706.html:text/html},
	url = {http://arxiv.org/abs/1706.02677},
}
@article{dutta_tinyml_2021,
	title = {{TinyML} Meets {IoT}: A Comprehensive Survey},
	volume = {16},
	issn = {2542-6605},
	doi = {10.1016/j.iot.2021.100461},
	shorttitle = {{TinyML} Meets {IoT}},
	abstract = {The rapid growth in miniaturization of low-power embedded devices and advancement in the optimization of machine learning ({ML}) algorithms have opened up a new prospect of the Internet of Things ({IoT}), tiny machine learning ({TinyML}), which calls for implementing the {ML} algorithm within the {IoT} device. {TinyML} framework in {IoT} is aimed to provide low latency, effective bandwidth utilization, strengthen data safety, enhance privacy, and reduce cost. Its ability to empower the {IoT} device to reliably function without consistent access to the cloud services while delivering accurate {ML} services makes it a promising option for {IoT} applications seeking cost-effective solutions. Especially in settings where inadequate connectivity is common, {TinyML} aims to provide on-premise analytics which will add substantial benefit to {IoT} services. In this article, we introduce the definition of {TinyML} and provide background information on diverse related technologies stating their strengths and weaknesses. We then show how {TinyML}-as-a-service is implemented through efficient hardware-software co-design. This article also introduces the role of 5G in {TinyML}-{IoT} scenario. Furthermore, it touches on the recent progress in {TinyML} research in both academia and industry along with future challenges and opportunities. We believe that this review will serve as an information cornerstone for the {IoT} research community and pave the way for further research in this direction.},
	pages = {100461},
	journaltitle = {Internet of Things},
	author = {Dutta, Dr. Lachit and Bharali, Swapna},
	urldate = {2023-01-31},
	date = {2021-12-01},
	langid = {english},
        year = {2021},
        journal={Internet of Things},
        keywords = {hardware-software co-design, Internet of Things ({IoT}), tiny machine learning ({TinyML})},
	file = {ScienceDirect Full Text PDF:/Users/mojulian/Zotero/storage/CWXNKI5C/Dutta and Bharali - 2021 - TinyML Meets IoT A Comprehensive Survey.pdf:application/pdf;ScienceDirect Snapshot:/Users/mojulian/Zotero/storage/UN9FT3C9/S2542660521001025.html:text/html},
    url = {https://www.sciencedirect.com/science/article/pii/S2542660521001025},
}
@article{merenda_edge_2020,
	title = {Edge Machine Learning for {AI}-Enabled {IoT} Devices: A Review},
	volume = {20},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	doi = {10.3390/s20092533},
	shorttitle = {Edge Machine Learning for {AI}-Enabled {IoT} Devices},
	abstract = {In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors’ data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning “Hello World”.},
	pages = {2533},
	number = {9},
	journaltitle = {Sensors},
	author = {Merenda, Massimo and Porcaro, Carlo and Iero, Demetrio},
	urldate = {2023-02-01},
	date = {2020-01},
        year = {2020},
        journal = {Sensors},
	langid = {english},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, deep learning, edge devices, Internet of Things, machine learning},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/Y2AKS7LQ/Merenda et al. - 2020 - Edge Machine Learning for AI-Enabled IoT Devices .pdf:application/pdf},
	url = {https://www.mdpi.com/1424-8220/20/9/2533},
}
@inproceedings{cai_-device_2019,
	title = {On-Device Image Classification with Proxyless Neural Architecture Search and Quantization-Aware Fine-Tuning},
	eventtitle = {Proceedings of the {IEEE}/{CVF} International Conference on Computer Vision Workshops},
	pages = {0--0},
	author = {Cai, Han and Wang, Tianzhe and Wu, Zhanghao and Wang, Kuan and Lin, Ji and Han, Song},
        booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
	urldate = {2022-01-25},
	year = {2019},
	file = {Full Text PDF:/Users/mojulian/Zotero/storage/8XM7YMBS/Cai et al. - 2019 - On-Device Image Classification with Proxyless Neur.pdf:application/pdf;Snapshot:/Users/mojulian/Zotero/storage/Y424VLZ4/Cai_On-Device_Image_Classification_with_Proxyless_Neural_Architecture_Search_and_Quantization-A.html:text/html},
	url = {},
}
@online{noauthor_overview_nodate-1,
	title = {Overview - Spresense - Sony Developer World},
	url = {https://developer.sony.com/develop/spresense/},
	urldate = {2023-02-03},
	langid = {english},
}
@online{noauthor_adi_2022,
	title = {{ADI} {MAX}78000/{MAX}78002 Model Synthesis},
	url = {https://github.com/MaximIntegratedAI/ai8x-synthesis},
	abstract = {Quantization and Synthesis (Device Specific Code Generation) for {ADI}'s {MAX}78000 and {MAX}78002 {AI} Devices},
	publisher = {Analog Devices {AI}},
	urldate = {2022-05-08},
	date = {2022-04-27},
	note = {original-date: 2020-05-19T21:57:23Z},
	keywords = {ai, analog-devices, artificial-intelligence, deep-learning, machine-learning, max78000, max78002, maxim, maxim-integrated},
}